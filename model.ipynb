{"cells":[{"cell_type":"code","execution_count":null,"id":"955d3c1e","metadata":{"id":"955d3c1e"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"id":"giNExQkZpLlY","metadata":{"id":"giNExQkZpLlY"},"outputs":[],"source":["class CausalConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = nn.Conv2d(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=(3, 2),\n","            stride=(2, 1),\n","            padding=(0, 1)\n","        )\n","        self.activation = nn.ELU()\n","        self.drop = nn.Dropout(0.2)\n","\n","    def forward(self, x ,drop = False):\n","        x = self.conv(x)\n","        x = x[:, :, :, :-1]\n","\n","        x = self.activation(x)\n","        if drop:\n","            x = self.drop(x)\n","        return x\n","\n","\n","class CausalTransConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, output_padding=(0, 0)):\n","        super().__init__()\n","        self.conv = nn.ConvTranspose2d(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=(3, 2),\n","            stride=(2, 1),\n","            output_padding=output_padding\n","        )\n","        self.activation = nn.ELU()\n","        self.drop = nn.Dropout(0.2)\n","    def forward(self, x,is_last = False,drop = False):\n","        x = self.conv(x)\n","        x = x[:, :, :, :-1]\n","        if is_last==False:\n","            x = self.activation(x)\n","        if drop:\n","            x = self.drop(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"f58e4682","metadata":{"id":"f58e4682"},"outputs":[],"source":["class CRN_1(nn.Module):\n","    def __init__(self):\n","        super(CRN_1, self).__init__()\n","        # Encoder\n","        self.conv_block_1 = CausalConvBlock(2, 16)\n","        self.conv_block_2 = CausalConvBlock(16, 32)\n","        self.conv_block_3 = CausalConvBlock(32, 64)\n","        self.conv_block_4 = CausalConvBlock(64, 128)\n","        self.conv_block_5 = CausalConvBlock(128, 256)\n","\n","        # LSTM\n","        self.lstm_layer = nn.LSTM(input_size=1024, hidden_size=1024, num_layers=2, batch_first=True)\n","\n","        self.tran_conv_block_1 = CausalTransConvBlock(256 + 256, 128)\n","        self.tran_conv_block_2 = CausalTransConvBlock(128 + 128, 64)\n","        self.tran_conv_block_3 = CausalTransConvBlock(64 + 64, 32)\n","        self.tran_conv_block_4 = CausalTransConvBlock(32 + 32, 16, output_padding=(1, 0))\n","        self.tran_conv_block_5 = CausalTransConvBlock(16 + 16, 2)\n","\n","        self.linear = nn.Linear(161,161)\n","        self.drop = nn.Dropout(0.2)\n","    def forward(self, x):\n","        self.lstm_layer.flatten_parameters()\n","\n","        e_1 = self.conv_block_1(x)\n","        e_2 = self.conv_block_2(e_1)\n","        e_3 = self.conv_block_3(e_2)\n","        e_4 = self.conv_block_4(e_3)\n","        e_5 = self.conv_block_5(e_4)\n","\n","        batch_size, n_channels, n_f_bins, n_frame_size = e_5.shape\n","        lstm_in = e_5.reshape(batch_size, n_channels * n_f_bins, n_frame_size).permute(0, 2, 1)\n","        lstm_out, _ = self.lstm_layer(lstm_in)\n","        lstm_out = lstm_out.permute(0, 2, 1).reshape(batch_size, n_channels, n_f_bins, n_frame_size)\n","\n","        d_1 = self.tran_conv_block_1(torch.cat((lstm_out, e_5), 1))\n","        d_2 = self.tran_conv_block_2(torch.cat((d_1, e_4), 1))\n","        d_3 = self.tran_conv_block_3(torch.cat((d_2, e_3), 1))\n","        d_4 = self.tran_conv_block_4(torch.cat((d_3, e_2), 1))\n","        d_5 = self.tran_conv_block_5(torch.cat((d_4, e_1), 1))\n","        d_5 = d_5.permute(0,1,3,2)\n","        d_5 = self.linear(d_5)\n","        d_5 = d_5.permute(0,1,3,2)\n","        return d_5\n","#first"]},{"cell_type":"code","execution_count":null,"id":"3c3a3fb3","metadata":{"id":"3c3a3fb3"},"outputs":[],"source":["class CRN_2(nn.Module):\n","    def __init__(self):\n","        super(CRN_2, self).__init__()\n","        # Encoder\n","        self.conv_block_1 = CausalConvBlock(2, 16)\n","        self.conv_block_2 = CausalConvBlock(16, 32)\n","        self.conv_block_3 = CausalConvBlock(32, 64)\n","        self.conv_block_4 = CausalConvBlock(64, 128)\n","        self.conv_block_5 = CausalConvBlock(128, 256)\n","\n","        # LSTM\n","        self.lstm_layer = nn.LSTM(input_size=1024, hidden_size=1024, num_layers=2, batch_first=True)\n","\n","        self.tran_conv_block_1 = CausalTransConvBlock(256 + 256, 128)\n","        self.tran_conv_block_2 = CausalTransConvBlock(128 + 128, 64)\n","        self.tran_conv_block_3 = CausalTransConvBlock(64 + 64, 32)\n","        self.tran_conv_block_4 = CausalTransConvBlock(32 + 32, 16, output_padding=(1, 0))\n","        self.tran_conv_block_5 = CausalTransConvBlock(16 + 16, 2)\n","\n","    def forward(self, x):\n","        self.lstm_layer.flatten_parameters()\n","\n","        e_1 = self.conv_block_1(x)\n","        e_2 = self.conv_block_2(e_1)\n","        e_3 = self.conv_block_3(e_2)\n","        e_4 = self.conv_block_4(e_3)\n","        e_5 = self.conv_block_5(e_4)\n","\n","        batch_size, n_channels, n_f_bins, n_frame_size = e_5.shape\n","        lstm_in = e_5.reshape(batch_size, n_channels * n_f_bins, n_frame_size).permute(0, 2, 1)\n","        lstm_out, _ = self.lstm_layer(lstm_in)\n","        lstm_out = lstm_out.permute(0, 2, 1).reshape(batch_size, n_channels, n_f_bins, n_frame_size)\n","\n","        d_1 = self.tran_conv_block_1(torch.cat((lstm_out, e_5), 1))\n","        d_2 = self.tran_conv_block_2(torch.cat((d_1, e_4), 1))\n","        d_3 = self.tran_conv_block_3(torch.cat((d_2, e_3), 1))\n","        d_4 = self.tran_conv_block_4(torch.cat((d_3, e_2), 1))\n","        d_5 = self.tran_conv_block_5(torch.cat((d_4, e_1), 1),is_last = True)\n","\n","        return d_5\n"]},{"cell_type":"code","execution_count":null,"id":"ULQ9qxEhPiQp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2228,"status":"ok","timestamp":1749616096405,"user":{"displayName":"이채훈","userId":"14976066403014206527"},"user_tz":-540},"id":"ULQ9qxEhPiQp","outputId":"f4ddbc7d-5e97-4f3b-830d-a74cc60662cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4, 2, 161, 200])\n"]}],"source":["# x = torch.randn(4,2,161,200)\n","# model = CRN_2()\n","# y = model(x)\n","# print(y.shape)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"}},"nbformat":4,"nbformat_minor":5}